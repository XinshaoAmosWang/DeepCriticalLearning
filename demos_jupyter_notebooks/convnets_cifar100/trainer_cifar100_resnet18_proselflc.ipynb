{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import torch\n",
    "\n",
    "from proselflc.trainer.trainer_cnn_vision_derivedgrad import Trainer\n",
    "\n",
    "import pprint\n",
    "print = pprint.PrettyPrinter(indent=4).pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add params configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'batch_accumu_steps': 10,\n",
      "    'batch_size': 128,\n",
      "    'classes_per_batch': 64,\n",
      "    'counter': 'iteration',\n",
      "    'data_name': 'cifar100',\n",
      "    'device': 'gpu',\n",
      "    'eval_interval': 500,\n",
      "    'exp_base': 16,\n",
      "    'gamma': 0.1,\n",
      "    'logit_soften_T': 0.5,\n",
      "    'loss_mode': 'cross entropy',\n",
      "    'loss_name': 'proselflc',\n",
      "    'lr': 0.2,\n",
      "    'lr_scheduler': 'WarmupMultiStepSchedule',\n",
      "    'milestones': [20000, 30000],\n",
      "    'momentum': 0.9,\n",
      "    'network_name': 'resnet18',\n",
      "    'num_classes': 100,\n",
      "    'num_workers': 8,\n",
      "    'sampler': 'BalancedBatchSampler',\n",
      "    'symmetric_noise_rate': 0.4,\n",
      "    'total_epochs': 100,\n",
      "    'transit_time_ratio': 0.5,\n",
      "    'trust_mode': 'global*(1-H(p)/H(u))',\n",
      "    'warmup_epochs': 0,\n",
      "    'weight_decay': 0.002}\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params.update(\n",
    "    {\n",
    "        \"data_name\": \"cifar100\",\n",
    "        \"num_classes\": 100,  # 1000\n",
    "        \"device\": \"gpu\",\n",
    "        #\n",
    "        \"num_workers\": 8,\n",
    "        #\n",
    "        \"counter\": \"iteration\",\n",
    "        \"classes_per_batch\": 8,\n",
    "        #\n",
    "        # To get deterministic results, please uncomment the line below\n",
    "        # to set seed parameter.\n",
    "        # \"seed\": 123,\n",
    "    }\n",
    ")\n",
    "\n",
    "# data\n",
    "params[\"symmetric_noise_rate\"] = 0.4\n",
    "\n",
    "# network\n",
    "params[\"network_name\"] = \"resnet18\"\n",
    "\n",
    "# for the demo purpose, I set the total epochs to be small.\n",
    "params[\"total_epochs\"] = 100\n",
    "params[\"eval_interval\"] = 500 # iterations\n",
    "\n",
    "# batch\n",
    "params[\"batch_size\"] = 128\n",
    "params[\"sampler\"] = \"BalancedBatchSampler\"\n",
    "params[\"classes_per_batch\"] = 64\n",
    "\n",
    "# learning rate\n",
    "params[\"lr\"] = 0.2\n",
    "params[\"weight_decay\"] = 2e-3 # larger weight decay for resnet18\n",
    "params[\"lr_scheduler\"] = \"WarmupMultiStepSchedule\"\n",
    "params[\"warmup_epochs\"] = 0\n",
    "params[\"milestones\"] = [20000, 30000]\n",
    "\n",
    "# optimisation\n",
    "params[\"momentum\"] = 0.9\n",
    "params[\"batch_accumu_steps\"] = 10\n",
    "params[\"gamma\"] = 0.1\n",
    "\n",
    "# loss settings\n",
    "params[\"loss_mode\"] = \"cross entropy\"\n",
    "params[\"trust_mode\"] = \"global*(1-H(p)/H(u))\"\n",
    "params[\"loss_name\"] = \"proselflc\"\n",
    "params[\"transit_time_ratio\"] = 0.50\n",
    "params[\"exp_base\"] = 16\n",
    "params[\"logit_soften_T\"] = 0.5\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extra configurations to get deterministic results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "params[\"seed\"] = 123"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the folder to store intermediate and final results\n",
    "* First, run `sudo mkdir /home/proselflc_experiments/ && sudo chmod -R 777 /home/proselflc_experiments/` so that so you have the write permission.\n",
    "* Or set `WORK_DIR = \"/home/your_username/proselflc_experiments/\"`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/proselflc_experiments/\"\n",
    "#\n",
    "# use the time as a unique experiment identifier\n",
    "dt_string = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "summary_writer_dir = (\n",
    "    params[\"loss_name\"]\n",
    "    + \"_\"\n",
    "    + dt_string\n",
    ")\n",
    "params[\"summary_writer_dir\"] = (\n",
    "    WORK_DIR\n",
    "    + \"/\"\n",
    "    + params[\"data_name\"]\n",
    "    + \"_symmetric_noise_rate_\"\n",
    "    + str(params[\"symmetric_noise_rate\"])\n",
    "    + \"/\"\n",
    "    + params[\"network_name\"]\n",
    "    + \"/\"\n",
    "    + summary_writer_dir\n",
    ")\n",
    "if not os.path.exists(params[\"summary_writer_dir\"]):\n",
    "    os.makedirs(params[\"summary_writer_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init the trainer, and store the params configurations\n",
    "For each experiment, we have one unique result folder to store the params configurations and learning curves.\n",
    "Therefore, you can revisit any specific experiment whenever you need without losing any details."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(params=params)\n",
    "# params[\"milestones\"] was a list of integers, we convert it to a string before sinking.\n",
    "params[\"milestones\"] = str(params[\"milestones\"])\n",
    "dataframe = pandas.DataFrame(params, index=[0])\n",
    "dataframe.to_csv(\n",
    "    params[\"summary_writer_dir\"] + \"/params.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    "    sep=\"\\t\",\n",
    "    mode=\"w\",  #\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the trainer and save the final model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Network.....\n",
      "Iteration= (500,2)/(39000, 100), lr=0.2000, batch_mean_epsilon=0.0001, valid batch size=128.0000, batch_mean_gtrust=0.0004, batch_mean_etrust=0.2999\n",
      "clean_test: Loss= 3.8340, Accuracy= 0.1144, Entropy= 0.8909, Max_p= 0.0921,\n",
      "noisy_subset: Loss= 4.9377, Accuracy= 0.0094, Entropy= 0.9129, Max_p= 0.0754,\n",
      "clean_subset: Loss= 3.8530, Accuracy= 0.1179, Entropy= 0.9119, Max_p= 0.0761,\n",
      "cleaned_noisy_subset: Loss= 3.8923, Accuracy= 0.1112, Entropy= 0.9128, Max_p= 0.0755,\n",
      "Evaluating Network.....\n",
      "Iteration= (1000,3)/(39000, 100), lr=0.2000, batch_mean_epsilon=0.0002, valid batch size=128.0000, batch_mean_gtrust=0.0005, batch_mean_etrust=0.3115\n",
      "clean_test: Loss= 3.6348, Accuracy= 0.1639, Entropy= 0.8903, Max_p= 0.0958,\n",
      "noisy_subset: Loss= 4.9194, Accuracy= 0.0107, Entropy= 0.9083, Max_p= 0.0814,\n",
      "clean_subset: Loss= 3.6587, Accuracy= 0.1687, Entropy= 0.9070, Max_p= 0.0825,\n",
      "cleaned_noisy_subset: Loss= 3.7051, Accuracy= 0.1550, Entropy= 0.9081, Max_p= 0.0815,\n",
      "Evaluating Network.....\n",
      "Iteration= (1500,4)/(39000, 100), lr=0.2000, batch_mean_epsilon=0.0002, valid batch size=128.0000, batch_mean_gtrust=0.0006, batch_mean_etrust=0.3592\n",
      "clean_test: Loss= 3.4949, Accuracy= 0.1885, Entropy= 0.8788, Max_p= 0.1072,\n",
      "noisy_subset: Loss= 4.9362, Accuracy= 0.0109, Entropy= 0.8969, Max_p= 0.0935,\n",
      "clean_subset: Loss= 3.5040, Accuracy= 0.1992, Entropy= 0.8950, Max_p= 0.0953,\n",
      "cleaned_noisy_subset: Loss= 3.5609, Accuracy= 0.1873, Entropy= 0.8969, Max_p= 0.0936,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(\n\u001B[1;32m      3\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mnetwork,\n\u001B[1;32m      4\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_writer_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/model.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe experiment is finished with details sinked in \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m      8\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_writer_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      9\u001B[0m     )\n\u001B[1;32m     10\u001B[0m )\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ProSelfLC_tpami2release-X5r1NEDs/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1052\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1053\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "torch.save(\n",
    "    trainer.network,\n",
    "    params[\"summary_writer_dir\"] + \"/model.pt\",\n",
    ")\n",
    "print(\n",
    "    \"The experiment is finished with details sinked in {}\".format(\n",
    "        params[\"summary_writer_dir\"]\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
